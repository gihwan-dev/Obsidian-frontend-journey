특정 컨텍스트에 도움이 되는 AI 모델을 만들기 위해서, 종종 배경 지식에 접근하는 것이 요구된다. 예를들어, 고객 지원 챗봇이 특정 비지니스에 대한 지식을 필요로 하고, 법률 분석 봇은 방대한 과거 사례에 대한 지식이 필요하다.

개발자들은 주로 AI 모델의 지식을 Retrival-Augmented Generation(RAG)를 사용해서 향상시킨다. RAG는 지식 체계로부터 연관된 정보를 수집하는 방법이며, 모델의 응답 품질을 크게 향상시켜 준다. 문제는 전통적인 RAG 솔루션은 정보를 인코딩 할 때 맥락을 제거하며, 종종 연관된 정보 수집에 실패하게 만든다.

이번 포스트에서, 우리는 RAG의 검색 단계를 크게 개선하는 방법을 소개한다. 이 방법은 "Contextual Retrieval"이라고 하며, 두 가지 하위 기술인 Contextual Embeddings와 Contextual BM25를 사용한다. 이 방법을 사용하면 검색 실패 횟수를 49% 줄일 수 있고, 리랭킹과 결합하면 67% 까지 줄일 수 있다. 이는 검색 정확도의 상당한 향상을 의미하며, 곧 후속 작업의 성능 향상으로 직접 이어진다.

## 단순하게 방대한 프롬프트를 사용하는 방법
종종 가장 단순한 방식이 최선의 방식이다. 만약 지식 기반이 200,000 토큰(500 페이지 분량) 보다 작다면, RAG 또는 비슷한 방식 없이 그냥 전체 지식 기반을 프롬프트에 넣을수도 있다.

## RAG에 대한 기초: 더 큰 지식 베이스로 확장하기
컨텍스트 윈도우에 담을 수 없는 거대 지식 베이스를 위해 RAG는 전형적인 솔루션이다.

#n8n 