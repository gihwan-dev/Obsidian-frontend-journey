## 서론: 대규모 언어 모델에서의 "More is Different" 현상

1972년 노벨 물리학상 수상자 필립 앤더슨(P.W. Anderson)은 그의 영향력 있는 에세이 "More Is Different"에서 복잡계의 핵심 원리를 설파했다.1 시스템의 양적 복잡성 증가는 단순히 구성 요소의 특성을 외삽하는 것만으로는 예측할 수 없는, 근본적으로 새로운 질적 행동을 낳는다는 것이다. 물리학, 생물학, 컴퓨터 과학 등 여러 분야에서 오랫동안 연구되어 온 이 '창발(emergence)'의 개념은 오늘날 인공지능(AI) 연구의 최전선에 있는 대규모 언어 모델(Large Language Models, LLM)을 둘러싼 논쟁을 이해하는 데 핵심적인 지적 프레임워크를 제공한다.2

현대 LLM 개발의 중심에는 하나의 거대한 모순이 자리 잡고 있다. 한편으로는 모델의 성능이 규모에 따라 놀라울 정도로 '예측 가능하게' 향상된다는 '스케일링 법칙(Scaling Laws)'이 존재한다. 모델의 핵심 훈련 목표인 교차 엔트로피 손실(cross-entropy loss)과 같은 지표는 모델의 파라미터 수, 훈련 데이터의 양, 그리고 사용된 컴퓨팅 자원이 증가함에 따라 부드러운 멱법칙(power-law) 곡선을 그리며 개선된다.6 그러나 다른 한편으로는 특정 다운스트림 과제에 대한 성능이 마치 임계점을 넘어서는 순간, 무작위 추측 수준에서 갑자기 높은 정확도로 도약하는 '예측 불가능한' 창발적 특성(emergent abilities)이 관찰된다.2 이 예측 가능한 점진적 개선과 예측 불가능한 급진적 도약의 공존이야말로 이 보고서가 풀어내고자 하는 핵심적인 수수께끼다.

본 보고서는 '창발적 특성'을 단일하고 확정된 현상이 아닌, 모델의 규모, 훈련 동역학, 과제의 복잡성, 그리고 결정적으로 평가에 사용되는 방법론 간의 복잡한 상호작용의 결과물로 분석하고자 한다. 이를 위해 먼저 창발적 특성의 개념을 정의하고 그 존재를 뒷받침하는 초기 경험적 증거들을 살펴볼 것이다. 이어서 창발 현상이 놀랍게 보이는 배경이 되는 예측 가능한 스케일링 법칙의 세계를 탐구한다. 그 후, 창발이 실제 현상이 아닌 측정의 오류로 인한 '신기루'에 불과하다는 영향력 있는 반론을 비판적으로 검토하고, 마지막으로 훈련 동역학 및 모델 아키텍처와 관련된 잠재적 기저 메커니즘을 탐구하며 AI 개발과 안전성에 미치는 광범위한 영향을 논의할 것이다.

이러한 논의의 기저에는 중요한 관점이 존재한다. LLM에서의 '창발'이라는 개념 자체가 현재 우리가 가진 예측 모델, 즉 스케일링 법칙의 실패에 의해 정의된다는 점이다. 창발은 "더 많은 컴퓨팅이 더 나은 성능을 낳는다"는 우리의 이해가 무너지고 질적인 놀라움으로 대체되는 경계선을 나타낸다. 창발적 특성의 정의 자체가 "더 작은 규모 모델의 성능 개선을 단순히 외삽하여 예측할 수 없는 능력"이라는 점은 이를 명확히 보여준다.2 스케일링 법칙이 교차 엔트로피 손실과 같은 핵심 지표에 대해 부드러운 예측 곡선을 제공하는 반면 6, 특정 과제에서 이 곡선이 급격히 꺾이는 지점이 바로 '창발'로 명명된다. 따라서 창발에 대한 연구는 단순히 새로운 기술을 목록화하는 것을 넘어, 이 거대한 인공 시스템에 대한 우리 자신의 과학적 이해의 한계를 탐사하는 과정과 같다. 우리의 예측 도구가 정교해질수록, 우리가 '창발'이라고 간주하는 현상의 경계 또한 이동할 수 있으며, 이는 이 현상이 우리 자신의 예측 능력과 본질적으로 연결되어 있음을 시사한다.

## 제1장: 창발적 특성의 정의와 관찰

### 1.1. 창발의 기초적 정의

LLM 분야에서 창발적 특성에 대한 논의를 촉발시킨 것은 2022년 Wei 등이 발표한 논문으로, 여기서 창발적 특성은 "더 작은 규모의 모델에서는 존재하지 않지만, 더 큰 규모의 모델에서는 존재하는 능력"으로 명확하게 정의되었다.2 이 정의는 두 가지 핵심적인 특징을 내포한다.

첫째는 **날카로움(Sharpness)**이다. 이는 특정 과제에 대한 모델의 성능이 무작위 추측 수준에 머물다가 특정 규모의 임계점을 넘어서면서 거의 즉각적으로 그보다 훨씬 높은 수준으로 전환되는 현상을 의미한다.1 이러한 급격한 변화는 종종 물리학에서의 상전이(phase transition) 현상에 비유되는데, 예를 들어 물이 특정 온도에서 갑자기 얼음으로 변하는 것처럼 시스템의 질적 상태가 급변하는 것과 유사하다.7

둘째는 **예측 불가능성(Unpredictability)**이다. 이러한 날카로운 성능 도약은 더 작은 모델들의 성능 곡선을 외삽(extrapolate)하는 것만으로는 예측할 수 없다.2 스케일링 법칙이 전반적인 손실 감소는 예측할 수 있을지라도, 어떤 특정 능력이 어느 규모에서 나타날지는 미리 알기 어렵다는 것이다.

### 1.2. 경험적 증거: 창발적 과제의 분류

창발 현상에 대한 주장은 방대한 경험적 관찰에 의해 뒷받침된다. 특히 구글의 BIG-Bench와 Massive Multitask Language Understanding (MMLU)과 같은 대규모 벤치마크는 이러한 현상을 식별하는 주요 원천이 되었다.7 이들 벤치마크를 통해 100가지가 넘는 창발적 과제들이 발견되었으며, 이는 특정 능력이 특정 모델 규모에서 발현됨을 보여준다.

구체적인 예시를 살펴보면, 과제의 복잡성에 따라 창발이 나타나는 임계점이 다르다는 것을 알 수 있다. 예를 들어, GPT-3 모델군에서는 3자리 덧셈/뺄셈 능력은 130억(13B) 파라미터 모델에서 나타나지만, 더 복잡한 4~5자리 연산은 1750억(175B) 파라미터 모델에 이르러서야 발현된다.13 다른 모델군에서도 유사한 패턴이 관찰된다. LaMDA 137B 모델에서는 아이러니 식별(irony identification) 능력이, PaLM 540B 모델에서는 초등 수학 질의응답(elementary math QA) 능력이 나타나며, Chinchilla 7B 모델에서는 전문 의학(professional medicine) 지식과 관련된 과제 수행 능력이 창발적으로 등장한다.13 이는 단순히 모델이 커지는 것이 아니라, 특정 수준의 복잡성을 처리할 수 있는 역량이 특정 규모에서 질적으로 변화함을 시사한다.

### 1.3. 과제를 넘어서: 창발적 프롬프팅 전략

창발 현상은 특정 과제에만 국한되지 않고, 모델의 추론 능력을 이끌어내는 일반적인 **전략(strategies)**에도 적용된다. 이러한 창발적 프롬프팅 전략은 작은 모델에서는 효과가 없거나 오히려 성능을 저하시키지만, 일정 규모 이상의 모델에서는 성능을 극적으로 향상시키는 강력한 도구가 된다.13

가장 대표적인 예는 **연쇄적 사고 프롬프팅(Chain-of-Thought Prompting, CoT)**이다. 이는 모델에게 최종 답변을 내놓기 전에 문제 해결을 위한 중간 추론 단계를 생성하도록 유도하는 기법이다. 이 능력은 LaMDA 모델군에서 약 680억(68B) 파라미터 규모에서 창발적으로 나타나는 것으로 관찰되었으며, 다단계 추론이 필요한 산수 문제나 논리 문제에서 특히 강력한 성능 향상을 이끌어냈다.9

CoT 외에도 다양한 창발적 프롬프팅 전략이 존재한다. 예를 들어, 명시적인 지시사항을 따르는 능력(Instruction-following)은 FLAN 68B 모델에서, 복잡한 문제를 더 쉬운 하위 문제로 분해하여 순차적으로 해결하는 최소-최대 프롬프팅(Least-to-most prompting)은 GPT-3 175B 모델에서, 여러 추론 경로를 생성해 다수결로 답을 정하는 자기 일관성(Self-consistency)은 LaMDA 68B 모델에서 효과를 발휘하기 시작한다.13 이러한 전략들의 존재는 모델의 규모가 커짐에 따라 단순히 지식을 더 많이 저장하는 것을 넘어, 내재된 지식을 활용하고 조작하는 메타-인지적 능력이 발현됨을 보여준다. 아래 표 1은 관찰된 창발적 특성들의 일부를 정리한 것이다.

|능력 유형|구체적 과제/전략|모델군|관찰된 창발 규모 (파라미터)|
|---|---|---|---|
|**Few-Shot 과제**|3자리 덧셈/뺄셈|GPT-3|13B|
||4-5자리 덧셈/뺄셈|GPT-3|175B|
||아이러니 식별|LaMDA|137B|
||초등 수학 QA|PaLM|540B|
||전문 의학|Chinchilla|7B|
||논리적 추론|GPT-3|175B|
||인과적 판단|PaLM|540B|
|**프롬프팅 전략**|연쇄적 사고 프롬프팅 (CoT)|LaMDA|68B|
||지시사항 준수 (Instruction-following)|FLAN|68B|
||최소-최대 프롬프팅|GPT-3|175B|
||자기 일관성 (Self-consistency)|LaMDA|68B|
||다국어 연쇄적 사고|PaLM|62B|

## 제2장: 예측 가능한 배경: 스케일링 법칙과 그 의미

### 2.1. 예측 가능한 개선의 시대

창발 현상이 그토록 놀랍고 예측 불가능하게 보이는 이유는, LLM 개발의 기저에 강력하고 예측 가능한 법칙이 존재하기 때문이다. **스케일링 법칙(Scaling Laws)**으로 알려진 이 경험적 관계는 모델의 핵심 성능 지표, 특히 다음 단어를 예측하는 능력의 척도인 교차 엔트로피 손실(cross-entropy loss)이 규모의 증가에 따라 부드럽고 예측 가능하게 개선된다는 것을 보여준다.6 이는 LLM이 무질서하게 발전하는 것이 아니라, 그 핵심 능력은 명확한 물리 법칙과 유사한 규칙성을 따른다는 것을 의미한다.

### 2.2. 스케일링의 세 가지 기둥

2020년 OpenAI의 Kaplan 등이 발표한 기념비적인 논문은 스케일링 법칙을 지배하는 세 가지 핵심 변수를 규명했다.6

1. **모델 크기 (N):** 임베딩을 제외한 모델의 학습 가능한 파라미터 수. 다른 요소가 충분할 때, 손실 $L(N)$은 파라미터 수 N에 대해 L(N)∝N−αN​ 형태의 멱법칙을 따른다.
    
2. **데이터셋 크기 (D):** 훈련에 사용된 텍스트 토큰의 총 개수. 마찬가지로, 손실 $L(D)$는 데이터셋 크기 D에 대해 L(D)∝D−αD​ 형태의 멱법칙을 따른다.
    
3. **훈련 컴퓨팅 (C):** 훈련에 소요된 총 부동소수점 연산(FLOPs). 손실 L(C) 또한 컴퓨팅 예산 C에 대해 L(C)∝C−αC​ 형태의 멱법칙을 따른다.
    

이 연구의 핵심적인 발견은 최적의 성능을 달성하기 위해서는 이 세 가지 요소를 함께 확장해야 한다는 것이다.6 어느 한 요소만 과도하게 늘리는 것은 비효율적이며, 세 변수 사이의 균형이 중요하다.

### 2.3. 법칙의 재정의: 친칠라(Chinchilla) 혁명

초기 스케일링 법칙은 '모델을 가능한 한 크게 만드는 것'에 초점을 맞추는 경향으로 이어졌다. 그러나 2022년 DeepMind의 Hoffmann 등은 '친칠라(Chinchilla)' 모델을 통해 이 패러다임에 중요한 수정을 가했다.9

이들의 핵심 주장은 GPT-3나 Gopher와 같은 이전의 거대 모델들이 컴퓨팅 예산에 비해 "덜 훈련되었다(undertrained)"는 것이었다.20 동일한 컴퓨팅 예산이 주어졌을 때, 가장 큰 모델을 만드는 것보다 약간 더 작은 모델을 훨씬 더 많은 데이터로 훈련시키는 것이 '컴퓨팅 최적(compute-optimal)' 전략이라는 점을 밝혔다. 구체적으로, 이들은 모델 크기가 두 배가 될 때마다 훈련 토큰의 수도 두 배로 늘려야 한다는 경험적 법칙을 제시했다.19

이 가설을 증명하기 위해, 연구팀은 2800억(280B) 파라미터의 Gopher와 동일한 컴퓨팅 예산을 사용하여 700억(70B) 파라미터의 친칠라 모델을 Gopher보다 4배 더 많은 데이터로 훈련시켰다. 그 결과는 놀라웠다. 친칠라는 자신보다 4배나 큰 Gopher는 물론, GPT-3(175B)를 포함한 다른 대형 모델들을 광범위한 벤치마크에서 일관되게 능가했다. 특히 MMLU 벤치마크에서는 Gopher보다 7% 이상 높은 정확도를 기록하며, 스케일링 법칙에 대한 이해를 한 단계 발전시켰다.19

### 2.4. 친칠라를 넘어서: '최적'의 진화하는 정의

친칠라 법칙은 한동안 LLM 훈련의 표준으로 여겨졌으나, 최근 연구는 '최적'의 정의가 또다시 진화하고 있음을 보여준다. 친칠라의 계산은 모델의 _훈련_ 비용에만 초점을 맞추고, 모델이 배포된 후 발생하는 _추론(inference)_ 비용을 간과했다는 비판이 제기되었다.18

Meta의 Llama와 같은 최신 모델들은 친칠라 법칙이 제안하는 것보다 훨씬 더 많은 데이터로 훈련된다.18 이는 특정 성능 수준에 도달하기 위한 훈련 비용을 증가시키지만, 결과적으로 더 작고 효율적인 모델을 만들어낸다. 수십억 건의 요청을 처리해야 하는 상용 서비스의 경우, 추론 비용 절감 효과가 추가적인 훈련 비용을 상쇄하고도 남기 때문에 이러한 전략은 경제적으로 합리적이다.18 이는 '최적' 스케일링이 훈련 예산뿐만 아니라 모델의 전체 생애주기 비용을 고려해야 함을 시사한다.

이처럼 스케일링 법칙이 핵심 지표에 대해 강력한 예측 가능성을 보여주면서, AI 연구 커뮤니티 내에서는 '규모가 핵심이다(scale is all you need)'라는 강력한 패러다임이 형성되었다. 이는 부드럽고 연속적인 성능 향상에 대한 강한 기대를 낳았다. 창발 현상은 바로 이 기대를 정면으로 위배하기에 단순한 흥밋거리를 넘어 과학적 이례(anomaly)로 받아들여진다. 시스템의 전역적 행동(손실)은 예측 가능한데, 국소적 행동(특정 과제 수행)이 예측 불가능하게 나타나는 것은 전역적 지표로는 포착되지 않는 질적 변화나 숨겨진 복잡성이 존재함을 암시한다.2 이 예측 가능성과의 극명한 대조가 창발 현상을 그토록 매력적으로 만드는 것이다. AI 안전성 관점에서 예측 가능성은 무엇보다 중요하다. 예측 가능하게 확장되는 시스템은 그 위험을 예측하고 관리할 수 있지만, 미지의 규모에서 예기치 않게 새로운 능력을 '잠금 해제'할 수 있는 시스템은 근본적인 통제와 정렬의 문제를 제기한다.1 따라서 스케일링 법칙의 존재 자체가 창발 현상을 단순한 호기심의 대상에서 중대한 안전성 문제로 격상시키는 필수적인 배경이 된다.

## 제3장: 거대한 논쟁: 창발적 특성은 신기루인가?

### 3.1. 비판의 핵심

창발 현상에 대한 열광적인 분위기 속에서, 2023년 Schaeffer 등이 발표한 논문은 학계에 큰 파장을 일으켰다. 이들의 핵심 주장은 창발적 특성이 LLM의 근본적인 속성이 아니라, 연구자가 성능을 측정하기 위해 선택한 **평가 지표(metric)에 의해 만들어진 신기루(mirage)**에 불과하다는 것이었다.1 즉, 모델의 실제 능력은 부드럽게 발전하고 있지만, 우리가 사용하는 '자'가 잘못되어 급격한 도약처럼 보인다는 것이다.

### 3.2. 지표가 만들어내는 환상

이 '신기루'가 발생하는 메커니즘은 평가 지표의 수학적 특성과 관련이 있다.

- **비선형적 지표 (예: 정확도)**: 여러 개의 토큰으로 구성된 정답을 맞춰야 하는 과제(예: 다자릿수 연산, 코드 생성)에서 '정확도(Accuracy)'는 모델의 개별 토큰 오류율에 대해 비선형적으로 작동한다. 모델의 토큰당 오류율이 규모에 따라 부드럽고 예측 가능하게 감소하더라도, 긴 시퀀스의 _모든_ 토큰을 정확히 맞출 확률은 개별 토큰의 정확도가 매우 높은 임계값을 넘기 전까지는 0에 가깝게 유지된다. 예를 들어, 토큰당 정답 확률이 p이고 길이가 L인 시퀀스의 정확도는 대략 pL에 비례한다. 이 기하급수적 관계 때문에 p가 점진적으로 증가해도 전체 과제의 정확도는 어느 순간 급격히 도약하는 것처럼 보인다.1
    
- **불연속적 지표 (예: 객관식 등급)**: 정답/오답과 같이 결과가 이진(binary)적인 지표는 불연속성을 만들어낸다. 예를 들어, '객관식 등급(Multiple Choice Grade)'은 정답 선택지에 할당된 확률이 가장 높을 때만 1점을 부여하고 나머지는 0점을 준다. 모델의 내부 확률 분포가 정답에 대해 40%에서 45%, 그리고 51%로 부드럽게 개선되더라도, 이 지표상에서는 다른 선택지의 확률을 넘어서는 순간 0점에서 1점으로 갑자기 점프하게 된다. 이 과정에서 부드러운 내부 능력의 향상은 가려지고 급작스러운 '창발'만 관찰된다. 한 메타 분석에 따르면 BIG-Bench에서 보고된 창발적 특성의 92% 이상이 이러한 불연속적 지표 하에서 나타났다.1
    

### 3.3. 신기루 걷어내기: 선형적, 연속적 지표의 효과

이러한 주장을 뒷받침하기 위해, 연구자들은 지표를 바꾸었을 때 창발 현상이 사라지는지를 실험적으로 보였다.

- **선형적 지표 (예: 토큰 편집 거리)**: 다자릿수 산술 과제를 '정확도' 대신 '토큰 편집 거리(Token Edit Distance)'로 재평가했다. 토큰 편집 거리는 모델의 출력과 정답 사이의 차이를 수정하는 데 필요한 편집(삽입, 삭제, 대체) 횟수로, 토큰당 오류율과 거의 선형적인 관계를 갖는다. 이 지표를 사용하자, GPT 모델군의 성능은 급격한 도약 없이 규모에 따라 부드럽고 예측 가능하게 향상되었다.1
    
- **연속적 지표 (예: 브라이어 점수)**: 객관식 과제의 경우, '객관식 등급' 대신 '브라이어 점수(Brier Score)'와 같은 연속적인 지표를 사용했다. 브라이어 점수는 확률 예측의 정확성을 연속적인 값으로 평가하여, 모델이 정답에 얼마나 확신을 가졌는지까지 측정한다. 이 지표로 바꾸자 불연속적인 점프는 사라지고, 역시 부드러운 성능 향상 곡선이 나타났다.23
    

### 3.4. 반론과 미묘한 지점들

'신기루' 가설이 매우 설득력 있음에도 불구하고, 모든 창발 현상을 설명하지는 못하며 논쟁은 계속되고 있다.

첫째, 프로그램 합성(program synthesis)과 같이 과제의 성공 여부가 본질적으로 이진적인 경우가 있다. 생성된 코드가 단위 테스트를 통과하는지 여부는 '거의 통과'라는 개념이 무의미한, 명백한 성공/실패다. 이런 경우 의미 있는 연속적 지표를 정의하기 어렵다.25

둘째, 일부 연구는 특정 능력이 발현되기 위해 최소한의 구조적 복잡성, 예를 들어 특정 개수 이상의 트랜스포머 레이어가 물리적으로 필요함을 시사한다. 예를 들어, 복잡한 정보 검색 과제는 여러 계층에 걸쳐 정보를 단계적으로 처리해야만 해결 가능할 수 있다. 이는 평가 지표의 문제가 아닌, 모델 아키텍처 자체에서 비롯되는 '구조적 창발'의 가능성을 제기하며 '신기루' 가설에 대한 강력한 반론이 된다.26

이 논쟁은 근본적으로 두 가지 상이한 관점의 충돌로 재해석될 수 있다. 하나는 실제 세계에서 중요한 **'과제 수준의 성공'**을 측정하려는 관점이고, 다른 하나는 스케일링의 과학을 이해하기 위해 **'기저 능력의 발전'**을 측정하려는 관점이다. 엔지니어나 최종 사용자는 모델이 문제를 정확히 풀었는지(이진적 결과)에 관심이 있다. 반면, LLM의 학습 과정을 모델링하려는 과학자는 내부 표현과 확률 분포의 점진적 개선에 더 관심이 있다. '신기루' 현상은 '과제 수준의 성공'을 측정하는 지표(예: 정확도)를 사용하여 '기저 능력의 발전' 과정에 대한 과학적 주장을 펼칠 때 발생한다. 따라서 논쟁의 핵심은 "창발은 실재하는가?"에서 "부드럽게 확장되는 기저 능력과 복잡한 과제에서의 급격한 성공 발현 사이의 관계는 무엇인가?"로 전환될 수 있다.

## 제4장: "왜"에 대한 탐구: 잠재적 메커니즘과 인과 관계

창발 현상이 단순한 신기루가 아니거나, 신기루라 할지라도 그 이면에 실제적인 메커니즘이 존재한다면, 그 원인은 무엇일까? 연구는 모델의 규모 자체를 넘어 더 근본적인 원인들을 탐색하고 있다.

### 4.1. 규모를 넘어: 사전 훈련 손실 임계값 가설

창발을 예측하는 더 정교한 지표로 **사전 훈련 손실(pre-training loss)**이 제안되었다. 이 가설에 따르면, 특정 능력은 특정 파라미터 수에서 나타나는 것이 아니라, 모델의 사전 훈련 손실 값이 특정 임계값 아래로 떨어졌을 때 발현된다.7 실제로 크기가 다른 모델이라도 동일한 손실 값까지 훈련시키면 다운스트림 과제에서 유사한 성능을 보이는 경향이 관찰되었다.9

이 관점은 창발을 모델의 원초적인 용량(capacity)이 아닌, 전반적인 학습 진행도 및 일반화 능력의 함수로 재정의한다. 이는 모델 크기와 데이터 양이 모두 최종 손실을 낮추는 데 기여하므로 두 효과를 우아하게 통합한다.7 또한, 훈련 동역학의 중요성을 부각시킨다. 예를 들어, 모델이 훈련 데이터의 특정 예시를 과도하게 암기(memorization)하는 데 치중하면 일반화 성능을 나타내는 손실 값의 감소가 지연되고, 결과적으로 창발적 특성의 발현 또한 늦춰질 수 있다.7

### 4.2. 기술 조합 가설

성능이 특정 임계점에서 급격히 도약하는 이유에 대한 강력한 기계론적 설명 중 하나는 **기술 조합(Composition of Skills)** 가설이다. 이 이론에 따르면, 많은 복잡한 과제는 단일 기술로 해결되는 것이 아니라, 여러 개의 더 단순한 기저 기술들의 조합을 요구하는 **다원적(polygenic)** 특성을 갖는다.14 예를 들어, 수학 응용 문제를 풀기 위해서는 (1) 문해력, (2) 필요한 수학 연산 식별 능력, (3) 실제 계산 수행 능력이라는 세 가지 하위 기술이 모두 필요하다.

이 경우, 전체 과제의 성능은 필요한 하위 기술 중 가장 취약한 하나에 의해 병목 현상을 겪는다. 모델이 모든 필수 하위 기술에서 최소한의 숙련도를 달성하기 전까지는 전체 과제 성공률이 거의 0에 머무를 것이다. '창발적 도약'은 마지막 병목 기술이 마침내 숙달되어, 모든 구성 요소가 성공적으로 조합될 수 있게 되는 바로 그 순간에 발생한다.4 이 가설은 '신기루' 비판과도 잘 연결된다. 개별 하위 기술들은 각각 규모에 따라 부드럽게(연속적 지표로 측정 가능하게) 향상될 수 있지만, 이들의 조합으로 이루어진 전체 과제의 성공(이진적 지표로 측정)은 모든 부품이 제대로 작동하기 시작할 때 비로소 나타나기 때문이다.

### 4.3. 아키텍처의 역할: 기계 속의 회로

창발의 근원을 이해하기 위해서는 LLM의 기반이 되는 트랜스포머(Transformer) 아키텍처 자체를 들여다봐야 한다.

- **셀프 어텐션 메커니즘:** 트랜스포머의 핵심인 셀프 어텐션(self-attention)은 시퀀스 내 모든 토큰 쌍 간의 관계를 동적으로 계산하여 문맥적 의미를 파악하는 강력한 메커니즘이다.28
    
- **회로의 창발:** 기계론적 해석 가능성(mechanistic interpretability) 연구는 모델이 확장됨에 따라 여러 층의 어텐션 헤드들이 조합되어 특정 알고리즘을 수행하는 복잡한 계산 **'회로(circuits)'**를 형성함을 보여준다. 예를 들어, 이전 패턴을 복사하는 기능을 수행하는 '유도 헤드(induction heads)'는 2개 층의 트랜스포머에서도 형성되는 것으로 알려져 있으며, 이는 문맥 내 학습(in-context learning)의 핵심 메커니즘으로 여겨진다.26
    
- **구조적 임계값:** 더 복잡한 과제, 예를 들어 여러 단계의 정보 검색이 필요한 문제는 해결을 위해 최소한의 레이어 수가 물리적으로 요구될 수 있다. 각 레이어가 순차적 계산의 한 단계를 수행하기 때문이다. 따라서 이러한 과제를 해결하는 능력은 다른 스케일링 요인과 무관하게 모델이 너무 '얕으면' 존재할 수조차 없는, **구조적 창발**의 한 형태라고 볼 수 있다.26
    

### 4.4. 데이터 품질과 다양성의 역할

지금까지의 논의는 주로 모델과 컴퓨팅에 초점을 맞추었지만, 훈련 데이터 자체의 역할 역시 간과할 수 없다. 스케일링 법칙이 데이터의 '양'에 집중하는 반면, 창발적 능력의 발현에는 데이터의 **품질, 다양성, 복잡성**이 결정적인 역할을 한다.31 다양성이 풍부한 데이터셋은 모델을 더 넓은 범위의 개념, 구조, 추론 패턴에 노출시킨다. 이는 일반화와 새로운 기술 형성의 원재료가 된다.31 방대한 웹 스케일 데이터는 모델에게 일종의 '암묵적 커리큘럼(implicit curriculum)'을 제공하여, 단순한 개념을 먼저 학습한 후 점차 복잡한 개념으로 나아가게 함으로써 창발적 행동에 필요한 하위 기술들의 점진적 발달을 촉진할 수 있다.31

이상의 논의들을 종합하면, 창발 현상에 대한 다층적인 통합 가설을 구성할 수 있다. 창발은 단일 원인에 의한 것이 아니라, 다음과 같은 인과 사슬의 결과로 이해할 수 있다. (1) 예측 가능한 **스케일링**은 사전 훈련 손실을 낮추며 학습의 엔진 역할을 한다. (2) 이 과정에서 트랜스포머 **아키텍처**는 특정 연산을 수행하는 계산 회로를 형성한다. (3) 이 회로들은 다양한 기저 **기술들**을 구현하며, 각 기술의 숙련도는 부드럽게 향상된다. (4) 복잡한 과제는 이러한 여러 기술의 **조합**을 요구하며, 가장 미숙한 기술에 의해 병목이 발생한다. (5) '창발의 순간'은 마지막 필수 기술이 성공적인 조합을 위한 신뢰도 임계값을 넘어서는 지점이다. (6) 이 임계점 통과를 성공/실패의 비선형적 **지표**로 관찰할 때, 이는 마치 갑작스럽고 예측 불가능한 상전이처럼 보이게 된다. 이 통합적 관점은 '신기루' 가설과 '실제 창발' 가설이 동일한 과정의 서로 다른 측면(관찰과 메커니즘)을 설명하고 있음을 보여주며, 두 관점을 화해시킨다.

## 제5장: 시사점과 향후 연구 방향

### 5.1. AI 안전성과 정렬에 대한 중대한 시사점

창발적 특성에 대한 학술적 논쟁은 AI의 미래와 관련된 심오하고 실질적인 결과를 함축하고 있다.

- **예측 불가능성의 문제:** 만약 고도의 기만, 조종, 자율적 해킹과 같은 잠재적으로 위험한 능력이 예측 불가능하게 더 큰 규모에서 창발할 수 있다면, 이는 알려진 위험을 테스트하는 데 의존하는 현재의 AI 안전 패러다임에 심각한 도전이 된다.1 창발의 존재는 더 작은 모델을 테스트하는 것만으로는 더 큰 모델의 안전을 보장할 수 없음을 의미한다.
    
- **균질화 위험:** 현대 AI 개발은 소수의 강력한 파운데이션 모델 위에 수많은 애플리케이션을 구축하는 '균질화(homogenization)' 경향을 보인다.36 만약 기반이 되는 파운데이션 모델에서 예기치 않은 유해한 능력이 창발한다면, 그 결함은 모든 하위 시스템으로 상속되어 사회적 규모의 단일 장애점(single point of failure)을 만들 수 있다.
    

### 5.2. 평가 및 벤치마킹의 재정의

창발 논쟁은 현재의 평가 방법론이 불충분함을 명확히 보여준다.

- **이진 지표를 넘어서:** 과제 수준의 성공으로 나타나기 전에 기저 능력의 점진적 개선을 감지할 수 있는 더 연속적이고 세분화된 지표를 개발하고 채택할 필요가 시급하다.1
    
- **예측적 스케일링:** 최근 연구는 과제의 하위 구성 요소에 대한 성능을 분석하거나, 시그모이드(sigmoid) 함수와 같은 더 정교한 곡선 피팅을 사용하여 작은 모델의 성능으로부터 창발 임계값을 예측하는 방법론 개발에 집중하고 있다.9
    

### 5.3. 미해결 문제와 연구의 최전선

본 보고서는 창발 현상을 둘러싼 가장 시급한 미해결 문제들을 제시하며 마무리하고자 한다.

- **기계론적 이해:** 궁극적인 목표는 창발을 관찰하고 예측하는 것을 넘어, 신경망 내부에서의 기계론적 토대를 완전히 이해하는 것이다. 기술들은 정확히 어떻게 조합되는가? 창발적 추론을 담당하는 특정 회로를 식별하고 그 발달을 제어할 수 있는가?.7
    
- **바람직한 능력 유도:** 기저 메커니즘에 대한 이해를 활용하여, 강력한 추론이나 진실성과 같은 바람직한 능력은 더 빠르고 작은 규모에서 창발하도록 유도하고, 바람직하지 않은 능력은 결코 발현되지 않도록 보장할 수 있는가?.1
    
- **스케일링의 미래:** 창발 현상은 어느 지점에서 정체될 것인가? 아니면 지속적인 스케일링이 훨씬 더 강력하고 질적으로 다른 능력을 계속해서 잠금 해제하여 모델을 범용 인공지능(AGI)에 더 가깝게 만들 것인가? 창발이 신기루이든 실재이든, 그 존재 자체가 스케일링의 이야기가 아직 끝나지 않았음을 강력하게 시사한다.2
    

아래 표 2는 본 보고서에서 논의된 창발 현상에 대한 주요 가설들을 요약한 것이다.

|가설명|핵심 주장|주요 근거|한계 및 반론|
|---|---|---|---|
|**상전이(Phase Transition)**|모델 규모가 임계점을 넘으면 질적으로 다른 행동이 갑자기 나타난다.|특정 과제에서 관찰되는 급격한 성능 도약 그래프.|현상에 대한 비유일 뿐, 구체적인 메커니즘을 설명하지 못함.|
|**지표 유도 신기루(Metric-Induced Mirage)**|창발은 비선형적/불연속적 평가 지표가 만들어낸 측정의 오류다.|선형적/연속적 지표(예: 토큰 편집 거리)로 변경 시 급격한 도약이 사라짐.|본질적으로 이진적인 과제(예: 코드 컴파일)에는 적용하기 어려움. 구조적 창발을 설명하지 못함.|
|**사전 훈련 손실 임계값**|능력은 모델 크기가 아닌, 사전 훈련 손실이 특정 임계값 아래로 떨어질 때 발현된다.|크기가 다른 모델도 동일 손실 값에서 유사한 성능을 보임.|손실과 능력 간의 상관관계는 명확하나, 직접적인 인과관계를 완전히 설명하지는 못함.|
|**기술 조합(Composition of Skills)**|복잡한 과제는 여러 하위 기술의 조합을 요구하며, 마지막 병목 기술이 숙달될 때 성능이 도약한다.|다단계 추론 과제에서 관찰되는 패턴. '신기루' 현상에 대한 기계론적 설명을 제공함.|어떤 하위 기술이 필요한지 사전에 정의하고 측정하기 어려움.|
|**아키텍처 회로(Architectural Circuits)**|스케일링을 통해 특정 알고리즘을 수행하는 계산 회로(예: 유도 헤드)가 신경망 내에 형성된다.|기계론적 해석 가능성 연구를 통해 특정 회로의 존재와 기능이 확인됨.|현재는 비교적 단순한 회로만 식별되었으며, 복잡한 추론 회로의 전체 구조는 아직 미지의 영역임.|