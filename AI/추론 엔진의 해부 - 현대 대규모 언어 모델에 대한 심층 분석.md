## 서론

ChatGPT와 같은 현대의 대규모 언어 모델(Large Language Models, LLM)이 보여주는 능력은 통계적 텍스트 예측이라는 단순한 원리에서 출발하여 복잡하고 인간과 유사한 추론을 수행하는 것처럼 보이는 경이로운 도약을 이루었습니다.1 이러한 현상은 많은 연구자와 개발자에게 핵심적인 역설을 제기합니다. 어떻게 확률적 다음 토큰 예측(next-token prediction) 메커니즘이 수학 문제를 풀고, 논리적 주장을 구성하며, 창의적인 글을 작성하는 등 구조화된 사고가 필요한 작업을 수행할 수 있는가에 대한 의문입니다. 이는 단순한 마법이 아니라, 혁신적인 아키텍처, 막대한 규모의 데이터, 그리고 새로운 훈련 패러다임이 복합적으로 작용한 결과입니다.

본 보고서는 LLM의 추론 현상을 체계적으로 해부하는 것을 목표로 합니다. 추론은 명시적으로 프로그래밍된 기능이 아니라, 트랜스포머(Transformer) 아키텍처가 데이터 내의 복잡한 종속성을 모델링하는 능력에서 비롯된 창발적 속성(emergent property)이며, 이후 정교한 프롬프팅 및 훈련 기법을 통해 유도되고, 구조화되며, 정제된다는 점을 논증할 것입니다. 이 보고서는 이러한 능력의 최전선을 탐구하고, 그 내재적 한계를 분석하며, 그 메커니즘을 이해하기 위한 현재 진행 중인 과학적 탐구를 심도 있게 다룰 것입니다.

보고서의 구성은 다음과 같습니다. 먼저, 추론 능력의 기반이 되는 트랜스포머 아키텍처를 분석하고(1장), 단순한 예측 작업에서 어떻게 추론 능력이 창발하는지 탐구합니다(2장). 이후, 이러한 잠재된 능력을 제어하고 구조화하는 프롬프팅 기법의 진화를 살펴보고(3장), 추론에 특화된 모델의 해부학적 구조를 정의합니다(4장). 다음으로, LLM의 '블랙박스' 문제와 이를 해결하기 위한 기계적 해석 가능성(mechanistic interpretability) 연구를 조명하고(5장), 마지막으로 확률적 패턴 매칭을 넘어선 기계 추론의 미래 방향성을 제시하며 마무리합니다(6장).

## 1장: 아키텍처의 초석: 트랜스포머가 복잡한 인지를 가능하게 하는 이유

LLM의 추론 능력을 이해하기 위한 첫걸음은 그 기반이 되는 트랜스포머 아키텍처, 특히 셀프 어텐션(self-attention) 메커니즘을 분석하는 것입니다. 이 아키텍처는 순환 신경망(RNN)이나 장단기 메모리(LSTM)와 같은 이전 모델들의 근본적인 한계를 극복하고, 데이터 내에서 복잡하고 장거리의 관계를 모델링할 수 있는 능력을 제공합니다. 이는 모든 형태의 논리적 추론을 위한 필수 전제 조건입니다.

### 1.1. 순차적 처리의 한계를 넘어서: RNN의 제약과 어텐션의 부상

RNN과 같은 초기 시퀀스-투-시퀀스(sequence-to-sequence) 모델은 데이터를 순차적으로 처리했습니다. 이러한 구조는 긴 시퀀스의 시작 부분에 있는 정보가 처리 과정에서 희석되어 제대로 보존되지 않는 '정보 병목(information bottleneck)' 문제를 야기했습니다.4 예를 들어, 긴 문단의 첫 문장에 제시된 전제와 마지막 문장의 결론을 연결하는 것은 RNN 구조에서는 매우 어려운 과제였습니다. 이러한 아키텍처의 한계는 멀리 떨어진 개념들을 연결해야 하는 복잡한 추론을 근본적으로 어렵게 만들었습니다.

이 문제에 대한 해결책으로 어텐션 메커니즘이 등장했습니다. 처음에는 기계 번역의 성능을 향상시키기 위해 개발되었으며, 모델이 출력 시퀀스의 각 부분을 생성할 때 입력 시퀀스의 모든 부분에 '다시 주목'할 수 있도록 허용했습니다.4 이는 모델이 장거리 종속성을 더 효과적으로 포착할 수 있게 만들었고, 이후 트랜스포머 아키텍처의 핵심 아이디어로 발전했습니다.

### 1.2. 셀프 어텐션 메커니즘: 동적 계산 그래프의 구축

트랜스포머의 핵심 혁신은 셀프 어텐션입니다. 이 메커니즘은 시퀀스 내의 각 토큰(단어 또는 단어의 일부)에 대해 쿼리(Query, Q), 키(Key, K), 밸류(Value, V)라는 세 가지 벡터를 계산합니다.5 작동 원리는 다음과 같습니다.

1. **어텐션 점수 계산:** 특정 토큰의 쿼리 벡터를 시퀀스 내의 다른 모든 토큰의 키 벡터와 비교(보통 내적 연산)하여 '어텐션 점수'를 계산합니다. 이 점수는 각 토큰 쌍 간의 관련성을 나타냅니다. 관련성이 높은 토큰 쌍은 높은 점수를 받습니다.5
    
2. **가중치 계산:** 이 점수들을 소프트맥스(softmax) 함수에 통과시켜 합이 1이 되는 확률 분포, 즉 '어텐션 가중치'로 변환합니다. 이 가중치는 특정 토큰을 처리할 때 다른 토큰들에 얼마나 많은 '주의'를 기울여야 하는지를 결정합니다.5
    
3. **컨텍스트 벡터 생성:** 마지막으로, 모든 토큰의 밸류 벡터를 해당 어텐션 가중치와 곱하여 가중합을 구합니다. 이렇게 생성된 벡터는 원래 토큰의 정보를 시퀀스 전체의 문맥 정보와 결합한 풍부하고 문맥화된 새로운 표현(representation)이 됩니다.5
    

이 과정은 시퀀스의 모든 토큰에 대해 동시에, 즉 병렬적으로 수행됩니다. 이는 순차적으로 처리해야 했던 RNN에 비해 엄청난 계산 효율성을 제공하며, 방대한 데이터셋에 대한 훈련을 가능하게 한 핵심 요인 중 하나입니다.5 "Attention Is All You Need"라는 논문에서 처음 제안된 트랜스포머 아키텍처는 순차적 처리에서 완전히 벗어난 패러다임의 전환을 의미했습니다.4

셀프 어텐션 메커니즘은 본질적으로 언어만을 위한 도구가 아니라, 범용적인 관계 모델링 엔진입니다. 시퀀스 내의 모든 요소가 다른 모든 요소와 관련하여 동적으로 중요도를 가중하는 능력은 추론 능력의 직접적인 아키텍처적 선행 조건입니다. 추론은 관련 정보 조각들을 식별하고 연결하는 과정인데, 이전 아키텍처는 정보 병목 현상으로 인해 이를 효과적으로 수행하지 못했습니다.4 반면, 셀프 어텐션은 모든 계층에서 각 토큰에 대해 모든 토큰 간의 완전하고 가중된 관계 그래프를 생성합니다.5 이를 통해 문단 시작의 전제와 끝의 결론 사이의 관계와 같은 복잡하고 비지역적인 종속성을 포착할 수 있습니다. 따라서 추론 능력은 나중에 추가된 기능이 아니라, 포괄적인 문맥 이해를 위해 설계된 아키텍처의 직접적인 결과물입니다.6 이 아키텍처적 기반 없이는 이후에 논의될 사고의 연쇄(Chain-of-Thought)와 같은 기법들도 효과를 발휘할 수 없습니다.

### 1.3. 멀티-헤드 어텐션과 레이어링: 다양한 관계 포착

트랜스포머는 셀프 어텐션의 능력을 더욱 확장하기 위해 멀티-헤드 어텐션(Multi-Head Attention)을 사용합니다. 이는 셀프 어텐션 과정을 여러 개의 '헤드'에서 병렬적으로 수행하는 것을 의미합니다. 각 헤드는 독립적으로 Q, K, V 행렬을 학습하며, 서로 다른 종류의 관계를 포착하도록 전문화됩니다. 예를 들어, 어떤 헤드는 문법적 종속성을, 다른 헤드는 의미적 유사성을, 또 다른 헤드는 위치적 관계를 학습할 수 있습니다.4 이렇게 여러 헤드에서 얻은 문맥 정보를 결합함으로써 모델은 단일 어텐션보다 훨씬 더 풍부하고 다각적인 시퀀스 표현을 구축할 수 있습니다.

또한, 트랜스포머는 이러한 멀티-헤드 어텐션 블록과 피드포워드 신경망(Feedforward Network)을 여러 층으로 쌓아 올린 구조를 가집니다. 이 깊은 구조를 통해 모델은 점진적으로 더 추상적이고 복잡한 표현을 학습합니다. 초기 레이어에서는 단어 간의 기본적인 구문 관계를 포착할 수 있고, 더 깊은 레이어로 갈수록 문장, 문단, 심지어 문서 전체에 걸친 정교한 의미적, 논리적 연결을 모델링할 수 있게 됩니다.9 이러한 계층적 정보 처리는 LLM이 단순한 패턴 인식을 넘어 복잡한 추론을 수행할 수 있는 기반을 마련합니다.

## 2장: 예측에서 추론의 창발

LLM의 핵심적인 훈련 목표는 '다음 토큰 예측'이라는 비교적 단순한 작업입니다. 그렇다면 어떻게 이 자기 지도 학습(self-supervised learning) 목표가 복잡한 추론 능력으로 이어질 수 있는가? 이 장에서는 사용자의 핵심적인 의문을 직접 다루며, 창발적 속성의 개념을 소개하고 그 이면에 있는 이론들을 탐구합니다.

### 2.1. 다음 토큰 예측의 역설

대부분의 LLM은 방대한 텍스트 코퍼스를 기반으로 다음 토큰을 예측하도록 훈련됩니다.10 이 과정은 겉으로 보기에 정교한 통계적 패턴 매칭이나 앵무새 같은 모방 행위에 지나지 않는 것처럼 보일 수 있습니다.3 실제로 모델은 '이해' 없이 가장 확률 높은 단어를 기계적으로 생성하는 것처럼 보입니다. 그러나 이러한 관점은 현상을 지나치게 단순화한 것입니다.12 다음 토큰 예측이라는 목표를 극단적으로 높은 수준으로 수행하기 위해서는, 모델이 단순히 표면적인 단어 연관성을 넘어 텍스트 이면에 있는 더 깊은 구조와 논리를 학습해야만 합니다.

### 2.2. 창발적 속성: 양적 확장이 질적 도약을 낳을 때

LLM의 '창발적 속성(emergent abilities)'은 모델의 규모(파라미터, 데이터, 훈련 컴퓨팅)가 특정 임계점을 넘어서면서, 작은 모델에서는 존재하지 않던 새로운 능력이 갑자기, 그리고 예측 불가능하게 나타나는 현상을 의미합니다.14 산술 연산, 다단계 추론, 그리고 문맥 내 학습(in-context learning) 등이 대표적인 창발적 속성의 예입니다.14

중요한 점은 이러한 능력들이 명시적으로 훈련된 것이 아니라, 모델 규모 확장의 부산물로 나타난다는 것입니다.14 예를 들어, 모델에게 덧셈을 가르치지 않았음에도, 방대한 텍스트 데이터에서 덧셈 예시를 학습함으로써 스스로 덧셈 규칙을 터득하게 됩니다. 이러한 현상이 진정한 의미의 '창발'인지, 아니면 우리의 평가 방식이 만들어낸 착시인지에 대한 논쟁은 여전히 진행 중입니다.19

### 2.3. 창발의 이론: 예측이 이해를 요구하는 이유

다음 토큰 예측이 어떻게 추론으로 이어지는지를 설명하는 몇 가지 주요 이론이 있습니다.

- **세계 모델 가설 (The World Model Hypothesis):** 과학 논문, 논리적 증명, 컴퓨터 코드 등 다양하고 복잡한 데이터셋에서 다음 토큰을 매우 정확하게 예측하기 위해서는, 모델이 언어의 표면적 패턴뿐만 아니라 그 이면에 있는 세계의 근본적인 규칙, 구조, 인과 관계에 대한 내재적 표현, 즉 '세계 모델(world model)'을 암묵적으로 학습하고 구축해야 한다는 주장입니다.12 물리학 증명의 다음 토큰을 예측하려면 물리학에 대한 내재적 모델이 필요하고, 코드의 다음 줄을 예측하려면 프로그래밍 논리에 대한 내재적 모델이 필요합니다. 즉, 정확한 예측은 세계에 대한 이해를 전제로 합니다.
    
- **다단계 추론 연쇄 효과 (The Multi-Step Reasoning Cascade):** 복잡한 문제는 여러 개의 간단한 추론 단계로 구성됩니다. 모델의 단일 추론 단계 성공률이 규모에 따라 점진적으로 향상되더라도, 이러한 단계를 여러 번 연속으로 성공해야 하는 전체 과제의 성공 확률은 단일 단계 성공률이 특정 임계점을 넘을 때 비선형적으로, 즉 급격하게 증가합니다. 이로 인해 해당 능력은 갑자기 나타나는 것처럼 보이게 됩니다.14
    
- **평가 지표가 만든 환상 (The Metric-Induced Illusion):** 창발 현상이 우리가 사용하는 평가 지표 때문에 발생하는 '신기루'일 수 있다는 반론도 존재합니다.17 예를 들어, '정확히 일치(exact match)'와 같이 성공 또는 실패만을 측정하는 불연속적인 지표는 점진적인 성능 향상을 포착하지 못하고, 성능이 0에서 갑자기 높은 정확도로 뛰어오르는 것처럼 보이게 만들 수 있습니다. 로그 우도(log likelihood)와 같이 더 연속적인 지표를 사용하면 때로는 더 완만한 성능 향상 곡선을 관찰할 수 있습니다.18
    

이러한 이론들을 종합해 볼 때, 추론은 LLM이 언어를 마스터한 후에 배우는 별개의 상위 기술이 아닙니다. 오히려, 기본적인 형태의 추론 능력은 다음 토큰 예측 과제 자체에서 최고 수준의 성능을 달성하기 위한 _필수 전제 조건_입니다. 모델이 예측을 더 잘하게 될수록, 그 내재적 세계 모델과 추론 능력은 더욱 정교해져야만 합니다. LLM의 훈련 데이터에는 수학적 증명, 법률적 논증, 복잡한 서사 등 수많은 복잡한 추론의 예시가 포함되어 있습니다. 이러한 시퀀스에서 다음 토큰을 정확하게 예측하기 위해 모델은 표면적인 통계에만 의존할 수 없습니다. 예측 오류(loss)를 최소화하는 가장 효율적인 방법은 텍스트 내의 논리적 흐름과 종속성을 포착하는 내재적 표현을 학습하는 것입니다.12 따라서 다음 토큰 예측의 최적화 과정은 모델이 추론과 세계 모델을 기능적으로 지원하는 내재적 구조를 개발하도록 장려합니다.21 이는 '창발적 속성'이 규모의 우연한 산물이 아니라, 모델이 데이터의 가장 압축되고 일반화 가능한 표현을 찾도록 강제하는 학습 과정의 예측 가능한 결과임을 시사합니다.

### 2.4. 다음 토큰 예측 패러다임의 한계

이처럼 강력함에도 불구하고, 다음 토큰 예측 목표는 특히 계획(planning)이나 선견(lookahead)이 필요한 작업에서 한계를 보입니다. 훈련 중에 사용되는 '교사 강제(teacher-forcing)' 방식, 즉 항상 정답인 이전 토큰들을 보여주며 다음 토큰을 예측하게 하는 방식은 모델이 견고한 계획 전략 대신 '클레버 한스(Clever Hans)'와 같은 편법적인 지름길을 배우도록 유도할 수 있습니다.22 클레버 한스는 주인의 미묘한 신호를 감지해 수학 문제를 푸는 것처럼 보였던 말의 이름에서 유래한 용어로, AI가 진정한 이해 없이 데이터의 피상적인 단서에 의존하는 현상을 비유합니다.

이러한 학습 방식은 모델이 처음부터 긴 시퀀스를 생성해야 할 때 효과적인 추론을 어렵게 만듭니다. 정답 접두사(ground-truth prefix)의 안내 없이 스스로 생성한 토큰을 기반으로 추론을 이어가야 하므로, 초기 단계의 작은 오류가 뒤로 갈수록 증폭될 수 있기 때문입니다.22 이는 추론 능력이 창발되기는 하지만, 다음 토큰 예측이라는 단일 목표만으로는 완벽하거나 효율적으로 학습되지 않음을 보여줍니다.

## 3장: 인지의 구조화: 지시에서 성찰로의 프롬프팅 진화

훈련을 통해 잠재된 추론 능력이 창발된다면, 우리는 추론 시점(inference time)에 어떻게 이 능력을 능동적으로 유도하고 안내할 수 있을까요? 이 장에서는 단순한 명령어에서부터 모델의 계산 과정을 구조화하는 복잡한 프레임워크에 이르기까지, 프롬프팅 기법의 진화 과정을 추적합니다. 이러한 기법들은 단순히 더 나은 지시를 내리는 것을 넘어, 강력하지만 비구조적인 확률 모델이 논리적 알고리즘을 모방하도록 계산 할당을 구조화하는 방법론입니다.

### 3.1. 제로샷에서 퓨샷으로: 문맥 내 학습

가장 기본적인 프롬프팅은 제로샷(Zero-shot)과 퓨샷(Few-shot)입니다. 제로샷은 모델에게 어떠한 예시도 없이 과제에 대한 지시사항만 제공하는 방식입니다. 반면, 퓨샷은 몇 개의 예시(exemplars)를 프롬프트에 포함하여 모델이 과제를 더 잘 이해하고 원하는 형식으로 응답을 생성하도록 유도하는 방식입니다.10 이는 더 발전된 기법들의 기초가 됩니다.

### 3.2. 사고의 연쇄(Chain-of-Thought) 프롬프팅: 모델이 "풀이 과정을 보이도록" 강제하기

사고의 연쇄(Chain-of-Thought, CoT)는 모델이 최종 답변을 내놓기 전에 복잡한 문제를 일련의 중간 논리 단계로 분해하도록 유도하는 프롬프팅 기법입니다.26 이는 일반적으로 "단계별로 생각해 보자(Let's think step by step)"와 같은 간단한 문구를 추가하거나(Zero-Shot CoT) 24, 단계별 풀이 과정을 보여주는 퓨샷 예시를 제공함으로써 이루어집니다.25

CoT가 효과적인 이유는 여러 가지입니다. 첫째, 문제 해결에 더 많은 계산을 할당하게 만듭니다. 즉, 더 긴 시퀀스를 생성하게 함으로써 모델이 '생각할 시간'을 더 많이 갖게 됩니다.28 둘째, 모델이 일관된 논리적 흐름을 유지하도록 강제합니다. 각 단계는 이전 단계에 기반하므로, 논리적 비약이나 모순이 발생할 가능성이 줄어듭니다.25 셋째, 생성된 중간 단계들은 트랜스포머의 셀프 어텐션 메커니즘에 추가적인 문맥을 제공하여, 후속 단계에서 관련 정보에 더 잘 집중할 수 있게 합니다.28 CoT 역시 창발적 속성으로, 모델의 규모가 클수록 그 효과가 극대화됩니다.16

### 3.3. 연쇄를 넘어서: 사고의 트리(Tree-of-Thoughts)와 사고의 그래프(Graph-of-Thoughts)

CoT의 선형적인 추론 과정에는 한계가 있습니다. 초기 단계에서 잘못된 길로 들어서면 전체 추론이 실패할 수 있습니다. 이러한 한계를 극복하기 위해 사고의 트리(Tree-of-Thoughts, ToT)가 제안되었습니다.29

ToT 프레임워크는 추론 과정을 나무 구조로 모델링합니다. 모델은 각 단계에서 여러 개의 가능한 다음 단계(생각)를 병렬적으로 탐색합니다. 마치 나무의 가지가 뻗어 나가듯이 말입니다. 이후, 각 경로의 유망성을 평가하고(상태 평가), 가능성이 높은 경로는 더 깊이 탐색하며, 막다른 길에 다다르면 이전 단계로 돌아가 다른 경로를 탐색(백트래킹)할 수 있습니다.31 이는 단 하나의 경로만 탐색하는 CoT와 달리, 체계적인 탐색 알고리즘(예: 너비 우선 탐색, 깊이 우선 탐색)을 통해 더 복잡하고 정답 경로가 명확하지 않은 문제(예: 계획 수립, 퍼즐 풀이)를 효과적으로 해결할 수 있게 합니다.32 이는 인간의 문제 해결 방식과 더욱 유사합니다.31

더 나아가, 사고의 그래프(Graph-of-Thoughts, GoT)는 서로 다른 추론 경로를 병합하거나 결합하여 생각의 네트워크를 구성하는, 훨씬 더 유연한 구조를 제안합니다.34

### 3.4. 자기 교정과 검증: 순환 고리 닫기

최신 연구는 모델이 자신의 작업을 비판하고 수정하도록 유도하는 기법으로 발전하고 있습니다. 자기 검증(Self-Verification)은 모델이 도출한 결론이 문제의 초기 조건과 일치하는지 스스로 확인하는 과정입니다.36 예를 들어, 수학 문제를 푼 뒤, 구한 답을 원래 식에 대입하여 등식이 성립하는지 검토하는 것과 같습니다.

S²R(Self-verify and Self-correct via Reinforcement Learning)과 같은 프레임워크는 이러한 반복적인 개선 기술을 모델에게 명시적으로 가르칩니다. 이는 단순한 프롬프팅을 넘어, 강화 학습을 통해 모델의 가중치에 자기 교정 능력을 내재화시키는, 더욱 견고하고 학습된 행동 양식입니다.37

이러한 고급 프롬프팅 기법들은 단순히 더 나은 지시를 제공하는 것을 넘어섭니다. 이들은 추론 시간 컴퓨팅의 할당을 구조화하는 방법론입니다. 표준 LLM이 복잡한 질문에 대해 통계적으로 그럴듯하지만 틀린 답을 내놓는 '지름길'을 택할 수 있는 반면, CoT는 중간 토큰 생성을 강제하여 계산 경로를 길게 만듭니다.26 이 과정에서 모델은 자신의 셀프 어텐션 메커니즘이 후속 단계에서 활용할 수 있는 더 많은 문맥을 스스로 제공하게 되어 논리적 일관성을 유지하기가 더 쉬워집니다.28 ToT는 여기서 한 걸음 더 나아가 계산 경로를 확장할 뿐만 아니라 넓혀서, LLM의 생성 과정을 핵심 연산자로 사용하는 탐색 알고리즘을 효과적으로 구현합니다.29 이를 통해 LLM은 단순한 생성기에서 신중한 문제 해결 프레임워크의 엔진으로 변모합니다.

다음 표는 논의된 추론 유도 기법들을 비교하여 각 방법의 메커니즘, 장단점, 그리고 이상적인 사용 사례를 명확히 보여줍니다.

|기능|표준 프롬프팅|사고의 연쇄 (CoT)|사고의 트리 (ToT)|
|---|---|---|---|
|**프로세스 구조**|직접적 (입력 → 출력)|선형적, 순차적 (입력 → 1단계 → 2단계 → 출력)|트리 기반, 병렬적 (입력 → 다중 경로 탐색 → 평가 → 백트래킹 → 출력)|
|**핵심 메커니즘**|지시 따르기|문제를 중간 단계로 분해 25|가능한 추론 경로에 대한 신중한 탐색 (예: BFS, DFS) 31|
|**오류 처리**|없음 (오류는 최종적)|제한적 (다음 단계에서 사소한 오류 수정 가능)|명시적 백트래킹 (실패한 전체 추론 경로 폐기 가능) 31|
|**계산 비용**|낮음|중간 (더 긴 시퀀스 생성)|높음 (여러 시퀀스를 병렬적으로 탐색) 32|
|**최적 사용 사례**|간단한 질의응답, 텍스트 생성|다단계 산술, 상식 추론 27|복잡한 계획, 퍼즐, 명확한 단일 경로가 없는 과제 32|

## 4장: 진정한 추론 모델의 해부

지금까지는 일반적인 LLM에서 프롬프팅을 통해 추론을 '유도'하는 방법을 살펴보았습니다. 그러나 연구의 최전선은 추론을 위해 명시적으로 미세 조정(fine-tuning)된, 진정한 의미의 '추론 언어 모델(Reasoning Language Model, RLM)' 또는 '추론 모델(Reasoning Model)'을 구축하는 방향으로 나아가고 있습니다. 이 장에서는 이러한 특화된 모델의 정의와 핵심 훈련 방법론을 분석합니다.

### 4.1. 추론 모델의 정의

추론 모델은 최종 출력을 생성하기 전에 복잡한 문제를 '추론 궤적(reasoning traces)'이라 불리는 더 작은 중간 단계로 분해하도록 특별히 미세 조정된 LLM입니다.39 프롬프팅과 달리, 이러한 행동은 모델의 가중치 자체에 내재되어 있습니다. 목표는 추론 시에 모델이 사용하는 컴퓨팅 양을 본질적으로 증가시키는 것입니다.40 이는 파라미터와 데이터 규모를 넘어선, '추론 시간 컴퓨팅(inference-time compute)'이라는 새로운 확장 차원을 제시합니다.41

### 4.2. 강화 학습(Reinforcement Learning)의 역할

추론 모델 훈련의 핵심 혁신은 새로운 강화 학습(RL) 기법의 적용에 있습니다.40 이 패러다임에서 모델은 추론 궤적을 생성하도록 훈련되며, 생성된 추론 과정이 얼마나 좋은지를 평가하는 '보상(reward)' 신호를 받습니다. 이후 모델의 가중치는 이 보상을 극대화하는 방향으로 조정됩니다.42 즉, 모델은 시행착오를 통해 더 나은 추론 방법을 스스로 학습하게 됩니다.

### 4.3. 보상은 과정이다: ORM 대 PRM

보상 신호를 설계하는 방식에 따라 크게 두 가지 접근법으로 나뉩니다.

- **결과 보상 모델 (Outcome Reward Models, ORM):** 가장 간단한 방식은 최종 결과에 기반하여 보상을 제공하는 것입니다. 답이 맞으면 높은 보상을, 틀리면 낮은 보상을 줍니다. 이를 결과 감독 강화 학습(outcome-supervised reinforcement learning)이라고도 합니다.40 정답 확인이 쉬운 과제(예: 수학 문제)에서는 이 방식을 자동화하기 용이합니다.42
    
- **과정 보상 모델 (Process Reward Models, PRM):** 이는 훨씬 더 정교한 접근법입니다. 여기서는 최종 결과와 상관없이, 추론 궤적의 _각 단계_가 논리적으로 타당하고 올바른 해결책으로 나아가는지에 따라 보상이 주어집니다.40 예를 들어, 풀이 과정의 한 줄이 수학적으로 올바르다면, 비록 최종 답이 틀렸더라도 그 단계에 대해서는 긍정적인 보상을 받을 수 있습니다.
    

PRM은 ORM보다 훨씬 강력한 학습 신호를 제공합니다. 이는 모델에게 단순히 정답을 우연히 찾는 법이 아니라, _올바르게 추론하는 방법_ 자체를 가르치기 때문입니다. 이 방식은 각 추론 단계에 대한 인간의 섬세한 레이블링을 필요로 하므로 비용이 많이 들 수 있지만, 더 신뢰할 수 있고 투명한 추론 능력을 모델에 내재화시킬 수 있습니다.42

이러한 PRM의 개발은 AI 훈련 방식의 근본적인 패러다임 전환을 의미합니다. 우리는 _결과_를 감독하는 것에서 _인지 과정_을 감독하는 것으로 나아가고 있습니다. 이는 단순히 인간의 출력을 모방하는 것을 넘어, 인간의 사고 과정을 모방하는 모델을 구축하기 위한 중요한 단계이며, 이를 통해 모델을 더 신뢰할 수 있고 감사 가능하게 만듭니다. 표준 딥러닝과 초기 LLM의 인간 피드백 강화 학습(RLHF)은 최종 출력에 초점을 맞춘 ORM 접근법이었습니다.42 그러나 모델은 잘못된 이유로 정답에 도달할 수 있으며(클레버 한스 효과), 이는 취약하고 신뢰할 수 없는 결과를 낳습니다.43 PRM은 훈련 목표를 변경하여, 나중에 실수가 발생하여 최종 답이 틀리더라도 논리적으로 타당한 단계를 생성한 것에 대해 모델에게 보상합니다.42 이 패러다임 전환이야말로 '추론 모델'을 표준 LLM과 진정으로 구별하는 요소이며, 순전히 상관관계에 기반한 시스템의 핵심 약점을 해결하려는 시도입니다.

### 4.4. 추론의 아키텍처: 구조 연산자

최첨단 추론 모델은 자신의 사고 과정을 조작할 수 있는 운영 도구 키트를 갖추고 있습니다. 이는 모델이 단순히 순차적으로 생각하는 것을 넘어, 더 동적이고 유연한 추론을 수행할 수 있게 합니다. 이러한 연산자(operator)들은 다음과 같습니다.34

- **생성 (Generate):** 새로운 추론 단계를 추가합니다.
    
- **정제 (Refine):** 기존 단계의 모호성을 해결하거나 오류를 수정하여 더 견고하게 만듭니다.
    
- **통합 (Aggregate):** 여러 단계나 경로의 정보를 결합하여 다음 단계를 생성합니다.
    
- **가지치기 (Prune):** 평가 지표에 따라 차선책이거나 관련 없는 것으로 판단되는 노드나 추론 단계를 제거합니다.
    
- **재구성 (Restructure):** 추론 구조에 임의의 변환을 적용하여 구성 요소를 유연하게 재구성합니다. 예를 들어, 트리 구조의 추론을 선형적인 연쇄로 변환할 수 있습니다.
    

이러한 연산자들을 통해 추론 모델은 마치 인간이 생각을 정리하고, 다듬고, 불필요한 아이디어를 버리는 것처럼 자신의 추론 과정을 능동적으로 관리하고 최적화할 수 있습니다.

## 5장: 블랙박스 딜레마: 기계적 해석 가능성과 회로 탐색

사용자가 지적했듯이 "인류는 이 모델들이 어떻게 작동하는지 완전히 이해하지 못한다"는 사실은 LLM 연구의 핵심적인 난제입니다. 이 장에서는 LLM이 왜 '블랙박스'로 간주되는지 설명하고, 이들을 역공학(reverse-engineering)하여 이해하려는 최첨단 연구 분야인 기계적 해석 가능성(Mechanistic Interpretability, MI)을 심도 있게 다룹니다.

### 5.1. 블랙박스의 본질

LLM의 내부 작동을 이해하기 어려운 이유는 복합적입니다.

- **규모와 복잡성:** LLM은 수십억에서 수조 개에 이르는 파라미터(가중치)를 가지고 있습니다. 이 파라미터들 간의 상호작용은 비선형적이고 복잡하여, 인간이 가중치를 직접 검사하여 입력에서 출력까지의 논리적 흐름을 추적하는 것은 불가능합니다.44
    
- **창발적 논리:** 추론을 포함한 모델의 능력은 명시적으로 코딩된 것이 아니라 전체 시스템의 창발적 속성입니다. 우리는 아키텍처와 훈련 데이터는 알지만, 모델이 그 과정에서 정확히 어떤 알고리즘을 학습했는지는 알지 못합니다.44
    
- **독점적 모델:** 가장 강력한 모델 중 다수는 독점적으로 개발되어 아키텍처, 훈련 데이터, 방법론 등이 영업 비밀로 유지됩니다. 이는 외부의 감사와 이해를 더욱 어렵게 만듭니다.44
    

### 5.2. 불투명성의 결과

이러한 불투명성은 여러 심각한 문제를 야기합니다.

- **신뢰도 저하 및 디버깅의 어려움:** 모델이 _왜_ 특정 답변을 했는지 알 수 없다면, 특히 의료나 금융과 같은 고위험 분야에서 그 결과를 신뢰하기 어렵습니다.43 모델이 실패했을 때, 내부 작동을 모르기 때문에 무엇이 잘못되었는지 정확히 찾아내어 수정하는 디버깅 과정이 극도로 어렵습니다.43
    
- **숨겨진 편향과 보안 위험:** 모델은 훈련 데이터에 존재하는 인간의 편향을 미묘한 방식으로 재현할 수 있으며, 투명성 없이는 이를 탐지하기 어렵습니다.43 또한 데이터 포이즈닝(data poisoning)이나 프롬프트 인젝션(prompt injection)과 같은 공격에 취약할 수 있습니다.43
    

### 5.3. 상자 열기: 설명 가능한 AI(XAI)와 해석 가능성

이러한 블랙박스 문제를 해결하기 위해 설명 가능한 AI(Explainable AI, XAI)라는 광범위한 연구 분야가 등장했습니다. XAI는 AI의 결정을 인간이 이해할 수 있도록 만드는 것을 목표로 합니다.49 초기 XAI 기법들은 다음과 같은 고수준의 해석 방법을 제공합니다.

- **행동 분석 (Behavioral Analysis):** 모델의 행동을 이해하기 위해 신중하게 설계된 입력(예: 적대적 예제)을 테스트하여 모델이 어떻게 반응하는지 관찰합니다.9
    
- **어텐션 분석 (Attention Analysis):** 어텐션 가중치를 시각화하여 모델이 입력의 어떤 부분에 '집중'하는지 확인합니다. 하지만 이것이 항상 모델의 추론 과정을 정확히 반영하는 것은 아니라는 한계가 있습니다.9
    

### 5.4. 최전선: 기계적 해석 가능성 (Mechanistic Interpretability, MI)

XAI가 고수준의 설명을 제공하는 반면, 기계적 해석 가능성(MI)은 훨씬 더 야심 찬 목표를 가집니다. 바로 신경망을 인간이 이해할 수 있는 알고리즘으로 완벽하게 역공학하는 것입니다.8 이는 컴파일된 기계어 코드를 다시 읽을 수 있는 소스 코드로 변환하는 것과 비유할 수 있습니다.

MI의 핵심 개념은 '회로(circuit)'입니다. 회로는 특정하고 이해 가능한 기능을 구현하는 뉴런과 어텐션 헤드의 특정 하위 그래프(subgraph)를 의미합니다.55 연구자들은 간접 목적어 식별, 감성 분석 등과 같은 작업을 수행하는 회로를 실제로 발견해냈습니다.9

그러나 MI 연구는 중대한 난관에 부딪힙니다. 바로 '다의미성(polysemanticity)'과 '중첩(superposition)'입니다. 다의미성은 단일 뉴런이 서로 관련 없는 여러 개념에 대해 활성화되는 현상이며, 중첩은 모델이 가진 뉴런 수보다 더 많은 특징을 여러 뉴런에 걸쳐 분산된 표현으로 나타내는 현상입니다. 이 두 가지 현상은 간단한 회로를 분리하고 해석하는 것을 매우 어렵게 만듭니다.8

기계적 해석 가능성은 LLM의 추론을 진정으로 이해하고 신뢰하기 위한 가장 유망한, 어쩌면 유일한 길일 수 있습니다. LIME이나 SHAP과 같은 전통적인 XAI 기법은 출력에 _어떤_ 입력 단어가 중요했는지를 보여줄 수 있지만, 그 단어들이 _어떻게_ 논리적으로 처리되었는지는 설명하지 못합니다.50 이는 상관관계에 기반한 설명이지, 인과관계에 기반한 설명이 아닙니다. MI는 논리적 연산(예: "만약 P이면 Q이다")을 위한 '회로'를 식별함으로써, 모델이 단순히 추측하는 것이 아니라 특정하고 반복 가능한 알고리즘을 구현하고 있음을 증명하고자 합니다.55 이는 "어떻게 작동하는지 모른다"는 패러다임에서 "이 작업을 위해 모델이 학습한 특정 알고리즘을 역공학했다"는 패러다임으로의 전환을 의미합니다. 따라서 MI의 발전은 안전하고 신뢰할 수 있는 AI 추론의 미래와 직접적으로 연결되어 있습니다. 좋은 추론을 위한 회로를 이해할 수 있다면, 결함 있는 추론을 디버깅하고, 편향된 회로를 제거하며, 심지어 훈련 중에 견고한 추론 회로의 형성을 장려할 수도 있을 것입니다.

## 6장: 기계 추론의 미래: 확률적 패턴 매칭을 넘어서

LLM의 추론 능력은 경이롭지만, 여전히 한계가 명확합니다. 이 장에서는 현재 LLM 추론의 한계를 살펴보고, 더 견고하고 신뢰할 수 있으며 강력한 추론 시스템을 만들기 위한 가장 유망한 미래 연구 방향을 탐구합니다. 미래의 첨단 AI 추론은 순수한 신경망 방식에만 머무르지 않을 가능성이 높습니다.

### 6.1. 현재의 한계: 취약성, 비일관성, 그리고 엄밀함의 부재

현재의 추론 모델들은 종종 취약한 모습을 보입니다. 문제의 표현 방식이 약간만 바뀌거나 관련 없는 정보가 추가되면 성능이 크게 저하될 수 있습니다.58 또한, 고등 수학 올림피아드 문제와 같이 엄격하고 형식적인 증명 기반 추론이 필요한 작업에서는 논리적 비약을 하거나 정당화되지 않은 가정을 하는 등 어려움을 겪습니다.61 근본적으로, 이들의 추론은 결정론적(deterministic)이지 않고 확률적(probabilistic)이라는 점에서, 완벽한 정확성이 요구되는 작업에는 치명적인 결함을 가집니다.58

### 6.2. 나아갈 길 1: 추론 학습과 추론 시간 확장

미래 연구의 한 축은 추론 시간 프롬프팅에서 벗어나, 모델에게 추론하는 법을 직접 가르치는 전용 훈련 체제로 이동하는 것입니다. 이는 강화 학습과 자동으로 생성된 방대한 양의 추론 데이터를 사용하여 이루어집니다.63 DeepSeek-R1과 같은 모델은 이러한 '추론 학습(learning-to-reason)' 접근법을 대표합니다.64 또한, '추론 시간 확장(test-time scaling)' 또는 '긴 생각(long thinking)' 개념은 더 어려운 문제를 해결하기 위해 추론 시에 계산 자원을 어떻게 최적으로 할당할 것인지 탐구하는 핵심 연구 분야로 남을 것입니다.41

### 6.3. 나아갈 길 2: 신경-상징 AI (Neuro-Symbolic AI)

신경-상징 AI는 신경망의 강점(패턴 인식, 원시 데이터로부터의 학습)과 상징 시스템의 강점(형식 논리, 검증 가능한 추론)을 결합하는 하이브리드 접근법입니다.60 이는 현재 패러다임의 근본적인 한계를 극복하기 위한 논리적인 다음 단계로 간주됩니다.

- **LLM을 의미 분석기로 활용:** LLM이 자연어 문제를 1차 논리(first-order logic)와 같은 형식적이고 상징적인 표현으로 번역합니다. 그 후, 결정론적인 외부 상징 해결기(symbolic solver)가 이 표현을 사용하여 해답을 찾습니다.62 이는 엄밀한 논리적 추론을 검증 가능한 도구에 위임하는 방식입니다.
    
- **상징 시스템으로 LLM 안내:** 지식 그래프(knowledge graph)와 같은 상징적 지식을 사용하여 LLM의 생성 과정을 안내하거나 제약함으로써, 환각(hallucination)을 줄이고 사실적 일관성을 보장합니다.69
    

LLM의 내재적인 확률적 특성과 취약성은 고위험 추론에서 인간 수준(또는 초인간 수준)의 신뢰성을 달성하기 위해 상징적이고 결정론적인 시스템과의 통합이 필요함을 시사합니다. 현재의 LLM은 완벽한 논리적 엄밀성이 요구되는 작업에서 실패하는데, 이는 이들이 형식 논리 엔진이 아니라 근본적으로 확률적 근사기이기 때문입니다.61 모델을 더 확장하더라도 이러한 근본적인 성격이 바뀔 가능성은 낮으며, '사전 훈련 고원(pre-training plateau)'에 가까워지고 있을 수 있습니다.41 반면, 정리 증명기나 논리 엔진과 같은 상징 AI 시스템은 형식 추론에는 완벽하지만, 자연어의 모호성을 다루지 못하고 확장성이 떨어집니다. 신경-상징 접근법은 LLM을 자연어 입력을 파싱하는 데 사용하고, 상징 엔진을 완벽하고 검증 가능한 논리적 단계를 실행하는 데 사용하는 '양쪽의 장점'을 취하는 아키텍처를 제안합니다.60 따라서 AI 추론의 궤적은 하이브리드 시스템을 향하고 있습니다. 궁극적인 '추론 모델'은 세계를 형식적 표현으로 번역하는 LLM 기반 프론트엔드와, 그 표현에 대해 완벽한 충실도로 추론하는 상징적 백엔드의 결합일 수 있습니다.

### 6.4. 나아갈 길 3: 에이전트 AI와 세계 모델

추론 모델을 인지적 핵심으로 사용하는 AI 에이전트의 개발도 활발히 진행되고 있습니다.70 이와 관련하여 명시적인 '세계 모델' 개념이 중요해지고 있습니다. 에이전트가 환경에 대한 내재적 시뮬레이션을 학습하게 되면, 자신의 내재적 모델 내에서 대안적인 행동을 탐색하고 미래 결과를 예측함으로써 신중한 계획을 수행할 수 있습니다.72 이는 정적인 텍스트에 대한 추론을 넘어, 동적인 상태에 대한 추론으로 나아가는 중요한 진전입니다.

## 결론

본 보고서는 트랜스포머 아키텍처의 잠재력에서부터 추론 모델의 명시적인 훈련에 이르기까지, LLM의 추론 능력에 대한 심층적인 분석을 제공했습니다. 추론은 통계적 예측이라는 기반 위에서 창발하는 속성이며, 구조화된 프롬프팅과 강화 학습을 통해 정제되지만, 여전히 그 확률적 기반으로 인한 근본적인 한계를 지니고 있음을 확인했습니다.

사용자의 초기 질문으로 돌아가자면, LLM이 추론할 수 있는 이유는 다음과 같이 요약할 수 있습니다. 첫째, 그 아키텍처(트랜스포머)가 복잡한 관계를 모델링하는 데 적합합니다. 둘째, 다음 토큰 예측이라는 대규모 훈련 목표는 모델이 성공하기 위해 내재적인 세계 모델을 구축하도록 강제합니다. 이렇게 잠재된 능력은 사고의 연쇄(CoT)와 같은 기법이나 과정 보상 모델(PRM) 기반 훈련을 통해 잠금 해제되고 구조화됩니다. 우리가 미시적인 수준에서 그 '방법'을 완전히 이해하지는 못하지만, 기계적 해석 가능성이라는 분야가 이러한 학습된 알고리즘을 역공학하려는 노력을 활발히 진행하고 있습니다.

결론적으로, 우리는 파라미터와 데이터의 규모를 확장하는 시대에서, 계산과 인지 아키텍처를 확장하는 시대로 이동하고 있습니다. AI의 미래는 세계의 가장 복잡한 문제들을 신뢰하고 맡길 수 있는, 더 신중하고, 검증 가능하며, 이해할 수 있는 추론 시스템을 구축하는 데 달려 있습니다. 이는 아마도 신경망 방식과 상징적 접근법의 통합을 통해 이루어질 가능성이 높습니다. 기계가 진정으로 '생각'하는 시대를 열기 위한 여정은 이제 막 시작되었습니다.